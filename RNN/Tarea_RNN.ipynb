{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtermor/NTIC_DeepLearning/blob/main/RNN/Tarea_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prospective-america",
      "metadata": {
        "id": "prospective-america"
      },
      "source": [
        "Dado que el entrenamiento de redes neuronales es una tarea  muy costosa, **se recomienda ejecutar el notebooks en [Google Colab](https://colab.research.google.com)**, por supuesto también se puede ejecutar en local.\n",
        "\n",
        "Al entrar en [Google Colab](https://colab.research.google.com) bastará con hacer click en `upload` y subir este notebook. No olvide luego descargarlo en `File->Download .ipynb`\n",
        "\n",
        "**El examen deberá ser entregado con las celdas ejecutadas, si alguna celda no está ejecutadas no se contará.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "novel-stewart",
      "metadata": {
        "id": "novel-stewart"
      },
      "source": [
        "El examen se divide en tres partes, con la puntuación que se indica a continuación. La puntuación máxima será 10.\n",
        "\n",
        "    \n",
        "- [Actividad 1: Redes Recurrentes](#actividad_1): 10 pts\n",
        "    - [Cuestión 1](#3.1): 2.5 pt\n",
        "    - [Cuestión 2](#3.2): 2.5 pt\n",
        "    - [Cuestión 3](#3.3): 2.5 pts\n",
        "    - [Cuestión 4](#3.4): 1.25 pts\n",
        "    - [Cuestión 5](#3.5): 1.25 pts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "prompt-developer",
      "metadata": {
        "id": "prompt-developer"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "regional-favorite",
      "metadata": {
        "id": "regional-favorite"
      },
      "source": [
        "<a name='actividad_1'></a>\n",
        "# Actividad 1: Redes Recurrentes\n",
        "\n",
        "\n",
        "- [Cuestión 1](#3.1): 2.5 pt\n",
        "- [Cuestión 2](#3.2): 2.5 pt\n",
        "- [Cuestión 3](#3.3): 2.5 pts\n",
        "- [Cuestión 4](#3.4): 1.25 pts\n",
        "- [Cuestión 5](#3.5): 1.25 pts\n",
        "\n",
        "Vamos a usar un dataset de las temperaturas mínimas diarias en Melbourne. La tarea será la de predecir la temperatura mínima en dos días. Puedes usar técnicas de series temporales vistas en otras asignaturas, pero no es necesario.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "empty-value",
      "metadata": {
        "id": "empty-value",
        "outputId": "67cab06f-63b9-4fce-868e-d96d4a52c5d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv\n",
            "67921/67921 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "dataset_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv'\n",
        "data_dir = tf.keras.utils.get_file('daily-min-temperatures.csv', origin=dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "numerous-situation",
      "metadata": {
        "id": "numerous-situation",
        "outputId": "11618a86-4b4e-406f-9ac4-23f8e6d85ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date  Temp\n",
              "0 1981-01-01  20.7\n",
              "1 1981-01-02  17.9\n",
              "2 1981-01-03  18.8\n",
              "3 1981-01-04  14.6\n",
              "4 1981-01-05  15.8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bb74cf5-5609-4dd9-82d7-5747f1f6f991\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Temp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1981-01-01</td>\n",
              "      <td>20.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1981-01-02</td>\n",
              "      <td>17.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981-01-03</td>\n",
              "      <td>18.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1981-01-04</td>\n",
              "      <td>14.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1981-01-05</td>\n",
              "      <td>15.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bb74cf5-5609-4dd9-82d7-5747f1f6f991')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7bb74cf5-5609-4dd9-82d7-5747f1f6f991 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7bb74cf5-5609-4dd9-82d7-5747f1f6f991');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3c7fb69-25a3-4a7e-92a8-b747214fcfaf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3c7fb69-25a3-4a7e-92a8-b747214fcfaf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3c7fb69-25a3-4a7e-92a8-b747214fcfaf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3650,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1981-01-01 00:00:00\",\n        \"max\": \"1990-12-31 00:00:00\",\n        \"num_unique_values\": 3650,\n        \"samples\": [\n          \"1984-08-06 00:00:00\",\n          \"1985-08-03 00:00:00\",\n          \"1981-08-18 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.071836899397183,\n        \"min\": 0.0,\n        \"max\": 26.3,\n        \"num_unique_values\": 229,\n        \"samples\": [\n          1.7,\n          14.5,\n          13.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv(data_dir, parse_dates=['Date'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "copyrighted-madonna",
      "metadata": {
        "id": "copyrighted-madonna",
        "outputId": "9359b4f5-964a-4f69-c974-2e5488e20b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of samples: 3650\n",
            "number of train samples: 3000\n",
            "number of test samples: 650\n",
            "firsts train samples: [20.7 17.9 18.8 14.6 15.8 15.8 15.8 17.4 21.8 20. ]\n"
          ]
        }
      ],
      "source": [
        "temperatures = df['Temp'].values\n",
        "print('number of samples:', len(temperatures))\n",
        "train_data = temperatures[:3000]\n",
        "test_data = temperatures[3000:]\n",
        "print('number of train samples:', len(train_data))\n",
        "print('number of test samples:', len(test_data))\n",
        "print('firsts train samples:', train_data[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adapted-brief",
      "metadata": {
        "id": "adapted-brief"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "## Cuestión 1: Convierta `train_data` y `test_data`  en ventanas de tamaño 5, para predecir el valor en 2 días\n",
        "\n",
        "En la nomenclatura de [Introduction_to_RNN_Time_Series.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Introduction_to_RNN_Time_Series.ipynb)\n",
        "```python\n",
        "past, future = (5, 2)\n",
        "```\n",
        "\n",
        "Para las primeras 10 muestras de train_data `[20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20. ]` el resultado debería ser:\n",
        "\n",
        "```python\n",
        "x[0] : [20.7, 17.9, 18.8, 14.6, 15.8] , y[0]: 15.8\n",
        "x[1] : [17.9, 18.8, 14.6, 15.8, 15.8] , y[1]: 17.4\n",
        "x[2] : [18.8, 14.6, 15.8, 15.8, 15.8] , y[2]: 21.8\n",
        "x[3] : [14.6, 15.8, 15.8, 15.8, 17.4] , y[3]: 20.             \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "conscious-teaching",
      "metadata": {
        "id": "conscious-teaching"
      },
      "outputs": [],
      "source": [
        "# Windowing function\n",
        "def create_windows_np(data, window_size, horizon, shuffle=False):\n",
        "    \"\"\"\n",
        "    Creates a dataset from the given time series data using NumPy.\n",
        "\n",
        "    Parameters:\n",
        "    data (np.ndarray): Time series data with one dimension.\n",
        "    window_size (int): The number of past time steps to use as input features.\n",
        "    horizon (int): The number of future time steps to predict.\n",
        "    shuffle (bool): Shuffle the windows or not.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the input-output pairs (windows, targets) as NumPy arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window_size - horizon + 1):\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size+horizon-1])\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "\n",
        "    if shuffle:\n",
        "        indices = np.arange(len(X))\n",
        "        np.random.shuffle(indices)\n",
        "        X, y = X[indices], y[indices]\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobar el resultado para las primeras 10 muestras\n",
        "Xt, yt = create_windows_np([20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20. ],\n",
        "                           window_size = 5,\n",
        "                           horizon = 2,\n",
        "                           shuffle=False)\n",
        "for ind in range(len(yt)):\n",
        "    print(Xt[ind, :], yt[ind])"
      ],
      "metadata": {
        "id": "axe201W5Ec2G",
        "outputId": "f64af667-dd0e-4917-b277-b330efe760df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "axe201W5Ec2G",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20.7 17.9 18.8 14.6 15.8] 15.8\n",
            "[17.9 18.8 14.6 15.8 15.8] 17.4\n",
            "[18.8 14.6 15.8 15.8 15.8] 21.8\n",
            "[14.6 15.8 15.8 15.8 17.4] 20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "joint-annotation",
      "metadata": {
        "id": "joint-annotation"
      },
      "outputs": [],
      "source": [
        "past, future = (5, 2)\n",
        "X_train, y_train = create_windows_np(train_data,\n",
        "                           window_size = past,\n",
        "                           horizon = future,\n",
        "                           shuffle=False)\n",
        "X_test, y_test = create_windows_np(test_data,\n",
        "                           window_size = past,\n",
        "                           horizon = future,\n",
        "                           shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "electrical-junior",
      "metadata": {
        "id": "electrical-junior"
      },
      "source": [
        "<a name='3.2'></a>\n",
        "## Cuestión 2: Cree un modelo recurrente de dos capas GRU para predecir con las ventanas de la cuestión anterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "aboriginal-complaint",
      "metadata": {
        "id": "aboriginal-complaint",
        "outputId": "7f99ef3e-b3b5-4846-8a81-71122b3a962c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 5, 1)]            0         \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 5, 64)             12864     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37889 (148.00 KB)\n",
            "Trainable params: 37889 (148.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.layers.Input(shape=(past, 1))\n",
        "\n",
        "GRU_1 = keras.layers.GRU(64, return_sequences=True)(inputs)\n",
        "GRU_2 = keras.layers.GRU(64, return_sequences=False)(GRU_1)\n",
        "\n",
        "outputs = layers.Dense(1)(GRU_2)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=keras.optimizers.Adam(), loss='mse')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "applicable-longer",
      "metadata": {
        "id": "applicable-longer",
        "outputId": "51f91f70-f857-4017-8717-75903ec7cd4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "38/38 [==============================] - 6s 24ms/step - loss: 40.4479 - val_loss: 16.8368\n",
            "Epoch 2/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 16.0726 - val_loss: 16.1170\n",
            "Epoch 3/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 13.8299 - val_loss: 13.1819\n",
            "Epoch 4/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 11.2317 - val_loss: 10.5913\n",
            "Epoch 5/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 9.7725 - val_loss: 9.2979\n",
            "Epoch 6/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 9.2637 - val_loss: 8.9224\n",
            "Epoch 7/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 9.0427 - val_loss: 8.8124\n",
            "Epoch 8/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.9682 - val_loss: 8.5113\n",
            "Epoch 9/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.9992 - val_loss: 8.8112\n",
            "Epoch 10/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.8390 - val_loss: 8.6773\n",
            "Epoch 11/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.8072 - val_loss: 8.5449\n",
            "Epoch 12/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.7632 - val_loss: 8.6499\n",
            "Epoch 13/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.7829 - val_loss: 8.3055\n",
            "Epoch 14/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.7756 - val_loss: 8.3472\n",
            "Epoch 15/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.7302 - val_loss: 9.1670\n",
            "Epoch 16/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.9196 - val_loss: 8.5403\n",
            "Epoch 17/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.7051 - val_loss: 8.4889\n",
            "Epoch 18/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.7695 - val_loss: 8.4996\n",
            "Epoch 19/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.7310 - val_loss: 8.2518\n",
            "Epoch 20/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.7383 - val_loss: 8.6383\n",
            "Epoch 21/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.6400 - val_loss: 8.1919\n",
            "Epoch 22/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.6962 - val_loss: 8.2015\n",
            "Epoch 23/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.6198 - val_loss: 8.5557\n",
            "Epoch 24/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.6670 - val_loss: 8.5271\n",
            "Epoch 25/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.6205 - val_loss: 8.3056\n",
            "Epoch 26/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.5664 - val_loss: 8.4146\n",
            "Epoch 27/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 8.6221 - val_loss: 8.8688\n",
            "Epoch 28/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 8.6688 - val_loss: 8.4162\n",
            "Epoch 29/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 8.6172 - val_loss: 8.2231\n",
            "Epoch 30/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 8.6295 - val_loss: 8.3026\n",
            "Epoch 31/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.7243 - val_loss: 8.4016\n"
          ]
        }
      ],
      "source": [
        "es_callback = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0, patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.2, shuffle=True, batch_size = 64, callbacks=[es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "stone-province",
      "metadata": {
        "id": "stone-province",
        "outputId": "2e7d9b32-d6ea-4b8a-9667-b1f939a7f76e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 4ms/step - loss: 6.9687\n",
            "Test Loss: 6.968696117401123\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "genetic-guitar",
      "metadata": {
        "id": "genetic-guitar"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "## Cuestión 3: Añada más features a la series temporal, por ejemplo `portion_year`. Cree un modelo que mejore al anterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "prospective-master",
      "metadata": {
        "id": "prospective-master"
      },
      "outputs": [],
      "source": [
        "## Puede añadir más features\n",
        "df['portion_year'] = df['Date'].dt.dayofyear / 365.0\n",
        "df_multi = df[['Temp', 'portion_year']].copy()\n",
        "\n",
        "## train - test split\n",
        "train_data = df_multi.iloc[:3000].copy()\n",
        "test_data = df_multi.loc[3000:, :].copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_windows_multivariate_np(data, window_size, horizon, target_col_idx, shuffle=False):\n",
        "    \"\"\"\n",
        "    Creates a dataset from the given time series data using NumPy.\n",
        "\n",
        "    Parameters:\n",
        "    data (np.ndarray or pd.DataFrame): Time series data with multiple features.\n",
        "    window_size (int): The number of past time steps to use as input features.\n",
        "    horizon (int): The number of future time steps to predict.\n",
        "    target_col_idx (int): The index of the target column in the input data.\n",
        "    shuffle (bool): Whether to shuffle the data or not.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the input-output pairs (X, y) as NumPy arrays.\n",
        "    \"\"\"\n",
        "    if isinstance(data, pd.DataFrame):\n",
        "        data = data.values\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window_size - horizon + 1):\n",
        "        X.append(data[i:i+window_size, :])\n",
        "        y.append(data[i+window_size+horizon-1, target_col_idx])\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "\n",
        "    if shuffle:\n",
        "        indices = np.arange(X.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        X, y = X[indices], y[indices]\n",
        "\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "M98FVt2LICc9"
      },
      "id": "M98FVt2LICc9",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "threaded-sheriff",
      "metadata": {
        "id": "threaded-sheriff"
      },
      "outputs": [],
      "source": [
        "## Create windows\n",
        "X_train, y_train = create_windows_multivariate_np(\n",
        "    train_data, past, future, target_col_idx=0, shuffle=True)\n",
        "\n",
        "X_test, y_test = create_windows_multivariate_np(\n",
        "    test_data, past, future, target_col_idx=0, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "stable-estate",
      "metadata": {
        "id": "stable-estate",
        "outputId": "09be0071-1506-4542-815a-807050072018",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 5, 2)]            0         \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 5, 64)             13056     \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38081 (148.75 KB)\n",
            "Trainable params: 38081 (148.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.layers.Input(shape=(past, X_train.shape[2]))\n",
        "\n",
        "GRU_1 = keras.layers.GRU(64, return_sequences=True)(inputs)\n",
        "GRU_2 = keras.layers.GRU(64, return_sequences=False)(GRU_1)\n",
        "\n",
        "outputs = layers.Dense(1)(GRU_2)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=keras.optimizers.Adam(), loss='mse')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "structured-philip",
      "metadata": {
        "id": "structured-philip",
        "outputId": "c5c28c28-c619-472f-c444-0d38754517b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "38/38 [==============================] - 4s 24ms/step - loss: 39.3963 - val_loss: 16.9322\n",
            "Epoch 2/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 16.1141 - val_loss: 15.8754\n",
            "Epoch 3/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 14.0486 - val_loss: 12.8490\n",
            "Epoch 4/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 11.5386 - val_loss: 10.8356\n",
            "Epoch 5/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 9.9917 - val_loss: 9.9499\n",
            "Epoch 6/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 9.2894 - val_loss: 9.3088\n",
            "Epoch 7/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.9864 - val_loss: 9.1115\n",
            "Epoch 8/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.9525 - val_loss: 8.9921\n",
            "Epoch 9/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.7764 - val_loss: 8.8934\n",
            "Epoch 10/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.7386 - val_loss: 8.9243\n",
            "Epoch 11/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.7146 - val_loss: 8.8282\n",
            "Epoch 12/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.6246 - val_loss: 8.9195\n",
            "Epoch 13/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 8.6822 - val_loss: 8.7653\n",
            "Epoch 14/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 8.6270 - val_loss: 8.7291\n",
            "Epoch 15/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.6333 - val_loss: 9.1937\n",
            "Epoch 16/200\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 8.6746 - val_loss: 8.8153\n",
            "Epoch 17/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 8.5812 - val_loss: 8.6513\n",
            "Epoch 18/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 8.6119 - val_loss: 8.6865\n",
            "Epoch 19/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.6100 - val_loss: 8.8310\n",
            "Epoch 20/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.5752 - val_loss: 8.7093\n",
            "Epoch 21/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.5830 - val_loss: 8.6207\n",
            "Epoch 22/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.6286 - val_loss: 8.6013\n",
            "Epoch 23/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.5307 - val_loss: 8.6358\n",
            "Epoch 24/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 8.5122 - val_loss: 8.5828\n",
            "Epoch 25/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.5321 - val_loss: 8.5829\n",
            "Epoch 26/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.4968 - val_loss: 8.6071\n",
            "Epoch 27/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.5302 - val_loss: 8.6021\n",
            "Epoch 28/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.5629 - val_loss: 8.6025\n",
            "Epoch 29/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.4733 - val_loss: 8.6784\n",
            "Epoch 30/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.4814 - val_loss: 8.5279\n",
            "Epoch 31/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.5668 - val_loss: 8.7202\n",
            "Epoch 32/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.4621 - val_loss: 8.5599\n",
            "Epoch 33/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.4779 - val_loss: 8.6890\n",
            "Epoch 34/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.5052 - val_loss: 8.5390\n",
            "Epoch 35/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.4532 - val_loss: 8.5332\n",
            "Epoch 36/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.4410 - val_loss: 8.5769\n",
            "Epoch 37/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.4433 - val_loss: 8.5421\n",
            "Epoch 38/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.4857 - val_loss: 8.7505\n",
            "Epoch 39/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.3938 - val_loss: 8.5091\n",
            "Epoch 40/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.5292 - val_loss: 8.6352\n",
            "Epoch 41/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.4424 - val_loss: 8.5251\n",
            "Epoch 42/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.3782 - val_loss: 8.4538\n",
            "Epoch 43/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.4489 - val_loss: 8.5145\n",
            "Epoch 44/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.4505 - val_loss: 8.7465\n",
            "Epoch 45/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.3777 - val_loss: 8.4807\n",
            "Epoch 46/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.3606 - val_loss: 8.6271\n",
            "Epoch 47/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.3996 - val_loss: 8.4954\n",
            "Epoch 48/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.3454 - val_loss: 8.5562\n",
            "Epoch 49/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.3511 - val_loss: 8.5010\n",
            "Epoch 50/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.3492 - val_loss: 8.6905\n",
            "Epoch 51/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.4381 - val_loss: 8.4472\n",
            "Epoch 52/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.3606 - val_loss: 8.8932\n",
            "Epoch 53/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.3505 - val_loss: 8.5219\n",
            "Epoch 54/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.2934 - val_loss: 8.4966\n",
            "Epoch 55/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.3048 - val_loss: 8.4886\n",
            "Epoch 56/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.3747 - val_loss: 8.4798\n",
            "Epoch 57/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.3474 - val_loss: 8.5277\n",
            "Epoch 58/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.2938 - val_loss: 8.5001\n",
            "Epoch 59/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 8.2734 - val_loss: 8.5158\n",
            "Epoch 60/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 8.2876 - val_loss: 8.5003\n",
            "Epoch 61/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.2464 - val_loss: 8.4136\n",
            "Epoch 62/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.2494 - val_loss: 8.4397\n",
            "Epoch 63/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.2885 - val_loss: 8.4544\n",
            "Epoch 64/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 8.2185 - val_loss: 8.4104\n",
            "Epoch 65/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.2334 - val_loss: 8.4572\n",
            "Epoch 66/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.2398 - val_loss: 8.4534\n",
            "Epoch 67/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.2392 - val_loss: 8.5187\n",
            "Epoch 68/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 8.3163 - val_loss: 8.4410\n",
            "Epoch 69/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.1703 - val_loss: 8.4460\n",
            "Epoch 70/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.1640 - val_loss: 8.5536\n",
            "Epoch 71/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.2271 - val_loss: 8.4394\n",
            "Epoch 72/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.1274 - val_loss: 8.4249\n",
            "Epoch 73/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.1297 - val_loss: 8.4733\n",
            "Epoch 74/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.1863 - val_loss: 8.3940\n",
            "Epoch 75/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.1295 - val_loss: 8.5736\n",
            "Epoch 76/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.1219 - val_loss: 8.4532\n",
            "Epoch 77/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.1579 - val_loss: 8.3977\n",
            "Epoch 78/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.0449 - val_loss: 8.3266\n",
            "Epoch 79/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8.0142 - val_loss: 8.6522\n",
            "Epoch 80/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 8.0310 - val_loss: 8.3309\n",
            "Epoch 81/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.9786 - val_loss: 8.2829\n",
            "Epoch 82/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.9573 - val_loss: 8.2581\n",
            "Epoch 83/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.8473 - val_loss: 8.2160\n",
            "Epoch 84/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.8248 - val_loss: 8.2003\n",
            "Epoch 85/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.6782 - val_loss: 8.1148\n",
            "Epoch 86/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 7.6097 - val_loss: 8.0523\n",
            "Epoch 87/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.6595 - val_loss: 8.0885\n",
            "Epoch 88/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.6699 - val_loss: 8.3315\n",
            "Epoch 89/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.5247 - val_loss: 8.1224\n",
            "Epoch 90/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.5033 - val_loss: 7.9103\n",
            "Epoch 91/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.5027 - val_loss: 8.4000\n",
            "Epoch 92/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.4519 - val_loss: 7.9317\n",
            "Epoch 93/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.4247 - val_loss: 7.8582\n",
            "Epoch 94/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.4603 - val_loss: 8.1187\n",
            "Epoch 95/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.3732 - val_loss: 7.9332\n",
            "Epoch 96/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.2861 - val_loss: 7.9470\n",
            "Epoch 97/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.2154 - val_loss: 8.1731\n",
            "Epoch 98/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.3670 - val_loss: 7.9706\n",
            "Epoch 99/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.2121 - val_loss: 7.8414\n",
            "Epoch 100/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.2093 - val_loss: 7.9057\n",
            "Epoch 101/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.1757 - val_loss: 8.0616\n",
            "Epoch 102/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.4247 - val_loss: 8.0460\n",
            "Epoch 103/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.2126 - val_loss: 8.0303\n",
            "Epoch 104/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 7.1677 - val_loss: 7.7998\n",
            "Epoch 105/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 7.0974 - val_loss: 8.1536\n",
            "Epoch 106/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 7.2121 - val_loss: 7.8384\n",
            "Epoch 107/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 7.0222 - val_loss: 7.8421\n",
            "Epoch 108/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 7.0357 - val_loss: 8.1186\n",
            "Epoch 109/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 7.0786 - val_loss: 7.9250\n",
            "Epoch 110/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 7.0516 - val_loss: 7.9160\n",
            "Epoch 111/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 7.0035 - val_loss: 7.8273\n",
            "Epoch 112/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.0326 - val_loss: 7.9709\n",
            "Epoch 113/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.0964 - val_loss: 7.7986\n",
            "Epoch 114/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 6.9806 - val_loss: 7.8572\n",
            "Epoch 115/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.1092 - val_loss: 7.8590\n",
            "Epoch 116/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 7.0104 - val_loss: 7.8950\n",
            "Epoch 117/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.0741 - val_loss: 8.2008\n",
            "Epoch 118/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.0265 - val_loss: 7.8611\n",
            "Epoch 119/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.0608 - val_loss: 7.8925\n",
            "Epoch 120/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 6.9954 - val_loss: 7.9230\n",
            "Epoch 121/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 7.0711 - val_loss: 8.1155\n",
            "Epoch 122/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 6.8613 - val_loss: 7.9223\n",
            "Epoch 123/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 6.9439 - val_loss: 8.2250\n"
          ]
        }
      ],
      "source": [
        "es_callback = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", min_delta=0, patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.2, shuffle=True, batch_size = 64, callbacks=[es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "assigned-afternoon",
      "metadata": {
        "id": "assigned-afternoon",
        "outputId": "7a7f6207-a17f-4814-ffa3-e8e5e2f43a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 3ms/step - loss: 6.4087\n",
            "Test Loss: 6.408729553222656\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test Loss: {}'.format(results))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loss con un single feature = 6.9687\n",
        "# Test loss con multiples features = 6.4087\n",
        "\n",
        "# Dado que el test loss es menor con múltiples features, el nuevo modelo (con\n",
        "# múltiples características) ha mejorado en comparación con el modelo anterior\n",
        "# (con una sola característica).\n"
      ],
      "metadata": {
        "id": "aM8eghk5L-PJ"
      },
      "id": "aM8eghk5L-PJ",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "precise-tract",
      "metadata": {
        "id": "precise-tract"
      },
      "source": [
        "<a name='3.4'></a>\n",
        "## Cuestión 4: ¿En cuáles de estas aplicaciones se usaría un arquitectura 'many-to-one'?\n",
        "\n",
        "**a)** Clasificación de sentimiento en textos\n",
        "\n",
        "**b)** Verificación de voz para iniciar el ordenador.\n",
        "\n",
        "**c)** Generación de música.\n",
        "\n",
        "**d)** Un clasificador que clasifique piezas de música según su autor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "professional-mayor",
      "metadata": {
        "id": "professional-mayor"
      },
      "source": [
        "La arquitectura \"many-to-one\" procesa una secuencia de datos y produce una única predicción o clasificación. Esta arquitectura se usaría en las siguientes aplicaciones:\n",
        "\n",
        "* **a) Clasificación de sentimientos en textos:** se procesa una secuencia de palabras (un texto) para producir una única salida que representa el sentimiento (por ejemplo, positivo o negativo). Es importante notar que si existiesen más categorías, el modelo no sería adecuado ya que no podría clasificar un elemento en varias categorías a la vez.\n",
        "* **b) Verificación de voz para iniciar el ordenador:** se analiza una secuencia de características de audio para verificar si la voz corresponde a una persona autorizada, produciendo una única salida de verificación.\n",
        "* **d) Un clasificador que clasifique piezas de música según su autor:** se analiza una secuencia de características de una pieza musical para producir una única salida que indique el autor.\n",
        "\n",
        "Sin embargo, la generación de música implica producir una secuencia de notas o sonidos, lo cual requiere una arquitectura 'many-to-many', donde tanto la entrada como la salida son secuencias."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fallen-error",
      "metadata": {
        "id": "fallen-error"
      },
      "source": [
        "<a name='3.5'></a>\n",
        "## Cuestión 5: ¿Qué ventajas aporta el uso de word embeddings?\n",
        "\n",
        "**a)** Permiten reducir la dimensión de entrada respecto al one-hot encoding.\n",
        "\n",
        "**b)** Permiten descubrir la similaridad entre palabras de manera más intuitiva que con one-hot encoding.\n",
        "\n",
        "**c)** Son una manera de realizar transfer learning en nlp.\n",
        "\n",
        "**d)** Permiten visualizar las relaciones entre palabras con métodos de reducción de dimensioones como el PCA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stylish-polish",
      "metadata": {
        "id": "stylish-polish"
      },
      "source": [
        "El uso de word embeddings aporta:\n",
        "* **a) Permiten reducir la dimensión de entrada respecto al one-hot encoding:** A diferencia del one-hot encoding, que representa cada palabra como un vector con una dimensión por cada palabra posible en el vocabulario, las word embeddings representan cada palabra como un vector con una dimensión mucho menor.\n",
        "\n",
        "* **b) Permiten descubrir la similaridad entre palabras de manera más intuitiva que con one-hot encoding:** Las word embeddings capturan las relaciones semánticas entre palabras, a través de representaciones vectoriales cercanas entre palabras con significados similares.\n",
        "\n",
        "* **c) Son una manera de realizar transfer learning en nlp:**  Las word embeddings entrenadas en un conjunto de datos grande se pueden utilizar para inicializar un modelo de aprendizaje automático para una tarea diferente.\n",
        "\n",
        "* **d) Permiten visualizar las relaciones entre palabras con métodos de reducción de dimensioones como el PCA:** Las word embeddings se pueden visualizar utilizando métodos de reducción de dimensionalidad como PCA, lo cual puede ser útil para comprender cómo el modelo de aprendizaje automático representa las relaciones semánticas entre palabras.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}